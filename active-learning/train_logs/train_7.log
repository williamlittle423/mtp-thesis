Selection data found
Basic trainer initialization complete
	auto-minmax-magmom = false
	init_random = false
	no_mindist_update = false
	skip_preinit = false
	iteration_limit = 1000
	weight_scaling = 1
	weight_scaling_forces = 0
	energy_weight = 1.000000
	force_weight = 0.010000
	penalty_weight = 0.000001
	scale_by_force = 0.000000
	select_factor = 1.000000
	stress_weight = 0.001000
	tolerance = 0.001000
	log = stdout
	save_to = mtp_V7.mtp
82 configurations found in the training set
Minimal interatomic distance in the training set is 1.54422. MTP's mindist will be updated
Iteration limit is 1000
Convergence tolerance is 0.001
Energy weight: 1
Force weight: 0.01
Stress weight: 0.001
MTPR training started on 1 core(s)
BFGS iter 0: f=0.0150724
BFGS iter 1: f=0.0150724
BFGS iter 2: f=0.0150724
BFGS iter 3: f=0.0150724
BFGS iter 4: f=0.0150724
BFGS iter 5: f=0.0150724
BFGS iter 6: f=0.0150724
BFGS iter 7: f=0.0150724
BFGS iter 8: f=0.0150724
BFGS iter 9: f=0.0150723
BFGS iter 10: f=0.0150719
BFGS iter 11: f=0.0150714
BFGS iter 12: f=0.0150713
BFGS iter 13: f=0.015071
BFGS iter 14: f=0.0150709
BFGS iter 15: f=0.0150708
BFGS iter 16: f=0.0150701
BFGS iter 17: f=0.0150696
BFGS iter 18: f=0.0150692
BFGS iter 19: f=0.0150689
BFGS iter 20: f=0.0150686
BFGS iter 21: f=0.0150683
BFGS iter 22: f=0.0150682
BFGS iter 23: f=0.015068
BFGS iter 24: f=0.0150679
BFGS iter 25: f=0.011299867
BFGS iter 26: f=0.011299867
BFGS iter 27: f=0.011299866
BFGS iter 28: f=0.011299866
BFGS iter 29: f=0.011299863
BFGS iter 30: f=0.011299851
BFGS iter 31: f=0.011299846
BFGS iter 32: f=0.011299837
BFGS iter 33: f=0.011299818
BFGS iter 34: f=0.011299771
BFGS iter 35: f=0.011299467
BFGS iter 36: f=0.011299104
BFGS iter 37: f=0.011298859
BFGS iter 38: f=0.011298691
BFGS iter 39: f=0.011298466
BFGS iter 40: f=0.011298421
BFGS iter 41: f=0.011298326
BFGS iter 42: f=0.011297787
BFGS iter 43: f=0.011297253
BFGS iter 44: f=0.011296821
BFGS iter 45: f=0.011296499
BFGS iter 46: f=0.011296083
BFGS iter 47: f=0.011295693
BFGS iter 48: f=0.011295552
BFGS iter 49: f=0.011295243
BFGS iter 50: f=0.011294973
BFGS iter 51: f=0.011294767
BFGS iter 52: f=0.011294518
BFGS iter 53: f=0.011294349
BFGS iter 54: f=0.011294263
BFGS iter 55: f=0.011294168
BFGS iter 56: f=0.011294051
BFGS iter 57: f=0.011293951
BFGS iter 58: f=0.011293837
BFGS iter 59: f=0.011293768
BFGS iter 60: f=0.011293704
BFGS iter 61: f=0.011293642
BFGS iter 62: f=0.011293583
BFGS iter 63: f=0.011293517
BFGS iter 64: f=0.011293391
BFGS iter 65: f=0.011293188
BFGS iter 66: f=0.011292978
BFGS iter 67: f=0.011292883
BFGS iter 68: f=0.011292828
BFGS iter 69: f=0.011292643
*
BFGS iter 70: f=0.011299331
BFGS iter 71: f=0.011299312
BFGS iter 72: f=0.011299229
BFGS iter 73: f=0.011298447
BFGS iter 74: f=0.011298264
BFGS iter 75: f=0.011298044
BFGS iter 76: f=0.011297819
BFGS iter 77: f=0.01129713
BFGS iter 78: f=0.011296325
BFGS iter 79: f=0.011296019
BFGS iter 80: f=0.011295737
BFGS iter 81: f=0.01129562
BFGS iter 82: f=0.011295459
BFGS iter 83: f=0.011295333
BFGS iter 84: f=0.011294278
BFGS iter 85: f=0.011293732
BFGS iter 86: f=0.011293367
BFGS iter 87: f=0.011292746
BFGS iter 88: f=0.011292007
BFGS iter 89: f=0.011291415
BFGS iter 90: f=0.011291139
BFGS iter 91: f=0.011290882
BFGS iter 92: f=0.011290334
BFGS iter 93: f=0.011289596
BFGS iter 94: f=0.011288401
BFGS iter 95: f=0.011287391
BFGS iter 96: f=0.011286894
BFGS iter 97: f=0.011286193
BFGS iter 98: f=0.011285784
BFGS iter 99: f=0.011285299
*
BFGS iter 100: f=0.01129492
BFGS iter 101: f=0.011294709
BFGS iter 102: f=0.01129439
BFGS iter 103: f=0.01129415
BFGS iter 104: f=0.011293984
BFGS iter 105: f=0.0112937
BFGS iter 106: f=0.011293493
BFGS iter 107: f=0.011293293
BFGS iter 108: f=0.011292875
BFGS iter 109: f=0.011292206
BFGS iter 110: f=0.011291833
BFGS iter 111: f=0.011291747
BFGS iter 112: f=0.011291627
BFGS iter 113: f=0.011291242
BFGS iter 114: f=0.011290883
BFGS iter 115: f=0.011290553
BFGS iter 116: f=0.011290334
BFGS iter 117: f=0.011290217
BFGS iter 118: f=0.011290162
BFGS iter 119: f=0.011290058
BFGS iter 120: f=0.011288856
BFGS iter 121: f=0.011287827
BFGS iter 122: f=0.011286883
BFGS iter 123: f=0.011285961
BFGS iter 124: f=0.011284808
BFGS iter 125: f=0.011282843
BFGS iter 126: f=0.011282264
BFGS iter 127: f=0.0112812
BFGS iter 128: f=0.011280605
BFGS iter 129: f=0.011279977
BFGS iter 130: f=0.011278948
BFGS iter 131: f=0.011278135
BFGS iter 132: f=0.011276047
BFGS iter 133: f=0.011275431
BFGS iter 134: f=0.011273262
BFGS iter 135: f=0.01127074
BFGS iter 136: f=0.01126779
BFGS iter 137: f=0.011266738
BFGS iter 138: f=0.011265739
BFGS iter 139: f=0.011264714
BFGS iter 140: f=0.011263981
BFGS iter 141: f=0.011263016
BFGS iter 142: f=0.011262442
BFGS iter 143: f=0.011261833
BFGS iter 144: f=0.011261562
BFGS iter 145: f=0.011261188
BFGS iter 146: f=0.011260772
BFGS iter 147: f=0.011260351
BFGS iter 148: f=0.011259704
BFGS iter 149: f=0.011259196
BFGS iter 150: f=0.011258764
BFGS iter 151: f=0.011258722
BFGS iter 152: f=0.011258706
BFGS iter 153: f=0.011258682
BFGS iter 154: f=0.011258653
BFGS iter 155: f=0.011258462
BFGS iter 156: f=0.011258289
BFGS iter 157: f=0.011258132
BFGS iter 158: f=0.011257917
BFGS iter 159: f=0.011257571
BFGS iter 160: f=0.011257041
BFGS iter 161: f=0.011256946
BFGS iter 162: f=0.011256864
BFGS iter 163: f=0.011256781
BFGS iter 164: f=0.011256541
BFGS iter 165: f=0.011255379
BFGS iter 166: f=0.011253616
BFGS iter 167: f=0.011252827
BFGS iter 168: f=0.011252646
BFGS iter 169: f=0.011252594
BFGS iter 170: f=0.011252575
BFGS iter 171: f=0.011252548
BFGS iter 172: f=0.011252458
BFGS iter 173: f=0.011252434
BFGS iter 174: f=0.011252414
BFGS iter 175: f=0.011252282
BFGS iter 176: f=0.011251627
BFGS iter 177: f=0.011249992
BFGS iter 178: f=0.011249747
BFGS iter 179: f=0.011248757
BFGS iter 180: f=0.011248469
BFGS iter 181: f=0.01124835
BFGS iter 182: f=0.011248005
BFGS iter 183: f=0.01124728
BFGS iter 184: f=0.011246723
BFGS iter 185: f=0.01124651
BFGS iter 186: f=0.011246392
BFGS iter 187: f=0.011246338
BFGS iter 188: f=0.011246237
BFGS iter 189: f=0.011246208
BFGS iter 190: f=0.011246196
BFGS iter 191: f=0.01124618
BFGS iter 192: f=0.01124611
BFGS iter 193: f=0.011246022
BFGS iter 194: f=0.011245976
BFGS iter 195: f=0.011245965
BFGS iter 196: f=0.011245959
BFGS iter 197: f=0.011245947
BFGS iter 198: f=0.011245811
BFGS iter 199: f=0.011244817
BFGS iter 200: f=0.01124375
BFGS iter 201: f=0.011242643
BFGS iter 202: f=0.011241592
BFGS iter 203: f=0.011241366
BFGS iter 204: f=0.01124107
BFGS iter 205: f=0.011240809
BFGS iter 206: f=0.011240635
BFGS iter 207: f=0.011240337
BFGS iter 208: f=0.011239964
BFGS iter 209: f=0.011238684
BFGS iter 210: f=0.01123773
BFGS iter 211: f=0.011237274
BFGS iter 212: f=0.011236431
BFGS iter 213: f=0.011236234
BFGS iter 214: f=0.011236034
BFGS iter 215: f=0.011235818
BFGS iter 216: f=0.011235542
BFGS iter 217: f=0.011235363
BFGS iter 218: f=0.011235168
BFGS iter 219: f=0.011234825
BFGS iter 220: f=0.01123432
BFGS iter 221: f=0.011233743
BFGS iter 222: f=0.011233043
BFGS iter 223: f=0.011232351
BFGS iter 224: f=0.011231849
BFGS iter 225: f=0.011231698
BFGS iter 226: f=0.011231439
BFGS iter 227: f=0.01123113
BFGS iter 228: f=0.011230889
BFGS iter 229: f=0.011230771
BFGS iter 230: f=0.011230648
BFGS iter 231: f=0.011230534
BFGS iter 232: f=0.011230315
BFGS iter 233: f=0.011230083
BFGS iter 234: f=0.011229739
BFGS iter 235: f=0.011229494
BFGS iter 236: f=0.011229322
BFGS iter 237: f=0.011229263
BFGS iter 238: f=0.011229183
BFGS iter 239: f=0.011229076
BFGS iter 240: f=0.011228809
BFGS iter 241: f=0.011228727
BFGS iter 242: f=0.011228667
BFGS iter 243: f=0.011228621
BFGS iter 244: f=0.011228603
BFGS iter 245: f=0.011228583
BFGS iter 246: f=0.011228566
BFGS iter 247: f=0.011228558
BFGS iter 248: f=0.011228555
BFGS iter 249: f=0.011228553
*
BFGS iter 250: f=0.011244658
BFGS iter 251: f=0.011244624
BFGS iter 252: f=0.011244593
BFGS iter 253: f=0.01124427
BFGS iter 254: f=0.011243482
BFGS iter 255: f=0.01124327
BFGS iter 256: f=0.011242941
BFGS iter 257: f=0.011242724
BFGS iter 258: f=0.01124241
BFGS iter 259: f=0.011241525
BFGS iter 260: f=0.011240904
BFGS iter 261: f=0.01124002
BFGS iter 262: f=0.011238558
BFGS iter 263: f=0.011237833
BFGS iter 264: f=0.011237589
BFGS iter 265: f=0.011237462
BFGS iter 266: f=0.011237432
BFGS iter 267: f=0.011237378
BFGS iter 268: f=0.011236838
BFGS iter 269: f=0.011236479
BFGS iter 270: f=0.011236293
BFGS iter 271: f=0.011236259
BFGS iter 272: f=0.011236147
BFGS iter 273: f=0.011235955
BFGS iter 274: f=0.011235839
BFGS iter 275: f=0.011235778
BFGS iter 276: f=0.011235624
BFGS iter 277: f=0.011235385
BFGS iter 278: f=0.011235235
BFGS iter 279: f=0.0112352
BFGS iter 280: f=0.011235165
BFGS iter 281: f=0.011234326
BFGS iter 282: f=0.011233203
BFGS iter 283: f=0.01123185
BFGS iter 284: f=0.011230891
BFGS iter 285: f=0.011230106
BFGS iter 286: f=0.011229285
BFGS iter 287: f=0.011228561
BFGS iter 288: f=0.011227502
BFGS iter 289: f=0.011226956
BFGS iter 290: f=0.011226227
BFGS iter 291: f=0.011226013
BFGS iter 292: f=0.011225698
BFGS iter 293: f=0.011225515
BFGS iter 294: f=0.011225344
BFGS iter 295: f=0.01122511
BFGS iter 296: f=0.01122498
BFGS iter 297: f=0.011224858
BFGS iter 298: f=0.011224781
BFGS iter 299: f=0.01122472
BFGS ended due to small decr. in 50 iterations
MTPR training ended
Rescaling...
   scaling = 0.031042179, condition number = 21.929806
   scaling = 0.033864195, condition number = 27.3789
   scaling = 0.037250615, condition number = 48.132857
   scaling = 0.040975676, condition number = 27.962554
   scaling = 0.044700738, condition number = 42.45749
Rescaling to 0.031042179... done
Rescaling...
   scaling = 0.025868483, condition number = 14.102641
   scaling = 0.028220163, condition number = 18.95647
   scaling = 0.031042179, condition number = 21.929998
   scaling = 0.034146397, condition number = 32.645854
   scaling = 0.037250615, condition number = 48.13285
Rescaling to 0.025868483... done
Rescaling...
   scaling = 0.021557069, condition number = 10.183433
   scaling = 0.023516802, condition number = 11.070389
   scaling = 0.025868483, condition number = 14.102641
   scaling = 0.028455331, condition number = 19.207133
   scaling = 0.031042179, condition number = 21.929998
Rescaling to 0.021557069... done
Rescaling...
   scaling = 0.017964224, condition number = 10.319797
   scaling = 0.019597335, condition number = 8.4638474
   scaling = 0.021557069, condition number = 10.183433
   scaling = 0.023712776, condition number = 11.184132
   scaling = 0.025868483, condition number = 14.102641
Rescaling to 0.019597335... done
Rescaling...
   scaling = 0.016331113, condition number = 9.0544961
   scaling = 0.017815759, condition number = 9.9835927
   scaling = 0.019597335, condition number = 8.4638474
   scaling = 0.021557069, condition number = 10.183433
   scaling = 0.023516802, condition number = 11.070276
Rescaling to 0.019597335... done
_________________Errors report_________________
Energy:
	Errors checked for 82 configurations
	Maximal absolute difference = 0.250757
	Average absolute difference = 0.0724155
	RMS     absolute difference = 0.12128

Energy per atom:
	Errors checked for 82 configurations
	Maximal absolute difference = 0.125378
	Average absolute difference = 0.0362504
	RMS     absolute difference = 0.0606406

Forces:
	Errors checked for 154 atoms
	Maximal absolute difference = 0.241958
	Average absolute difference = 0.0715903
	RMS     absolute difference = 0.105842
	Max(ForceDiff) / Max(Force) = 0.100352
	RMS(ForceDiff) / RMS(Force) = 0.0801711

Stresses (in energy units):
	Errors checked for 82 configurations
	Maximal absolute difference = 6.54148
	Average absolute difference = 2.02462
	RMS     absolute difference = 2.78306
	Max(StresDiff) / Max(Stres) = 1.12074
	RMS(StresDiff) / RMS(Stres) = 0.561652

Virial stresses (in pressure units):
	Errors checked for 82 configurations
	Maximal absolute difference = 168.561
	Average absolute difference = 50.2558
	RMS     absolute difference = 69.83
	Max(StresDiff) / Max(Stres) = 1.08712
	RMS(StresDiff) / RMS(Stres) = 0.561491
_______________________________________________

	batch_size = 9999
	swap_limit = 0
	weight_scaling = 2
	energy_weight = 1.000000
	force_weight = 0.000000
	init_value = 0.000001
	site_en_weight = 0.000000
	stress_weight = 0.000000
	threshold = 1.001000
Selection: state saved to "mtp_V7.mtp"
training complete
