Selection data found
Basic trainer initialization complete
	auto-minmax-magmom = false
	init_random = false
	no_mindist_update = false
	skip_preinit = false
	iteration_limit = 1000
	weight_scaling = 1
	weight_scaling_forces = 0
	energy_weight = 1.000000
	force_weight = 0.010000
	penalty_weight = 0.000001
	scale_by_force = 0.000000
	select_factor = 1.000000
	stress_weight = 0.001000
	tolerance = 0.001000
	log = stdout
	save_to = mtp_V36.mtp
353 configurations found in the training set
Minimal interatomic distance in the training set is 1.54422. MTP's mindist will be updated
Iteration limit is 1000
Convergence tolerance is 0.001
Energy weight: 1
Force weight: 0.01
Stress weight: 0.001
MTPR training started on 1 core(s)
BFGS iter 0: f=0.3689
BFGS iter 1: f=0.3689
BFGS iter 2: f=0.3689
BFGS iter 3: f=0.368899
BFGS iter 4: f=0.368898
BFGS iter 5: f=0.368898
BFGS iter 6: f=0.368898
BFGS iter 7: f=0.368897
BFGS iter 8: f=0.368897
BFGS iter 9: f=0.368897
BFGS iter 10: f=0.368897
BFGS iter 11: f=0.368896
BFGS iter 12: f=0.368896
BFGS iter 13: f=0.368894
BFGS iter 14: f=0.368891
BFGS iter 15: f=0.368891
BFGS iter 16: f=0.36889
BFGS iter 17: f=0.36889
BFGS iter 18: f=0.36889
BFGS iter 19: f=0.36889
BFGS iter 20: f=0.368889
BFGS iter 21: f=0.368889
BFGS iter 22: f=0.368889
BFGS iter 23: f=0.368889
BFGS iter 24: f=0.368889
BFGS iter 25: f=0.0079225642
BFGS iter 26: f=0.0079225372
BFGS iter 27: f=0.007922386
BFGS iter 28: f=0.0079223039
BFGS iter 29: f=0.0079207331
BFGS iter 30: f=0.0079205565
BFGS iter 31: f=0.0079202305
BFGS iter 32: f=0.0079199531
BFGS iter 33: f=0.0079198919
BFGS iter 34: f=0.0079198609
BFGS iter 35: f=0.0079196766
BFGS iter 36: f=0.0079189587
BFGS iter 37: f=0.0079183437
BFGS iter 38: f=0.0079170615
BFGS iter 39: f=0.0079137563
BFGS iter 40: f=0.0079136971
BFGS iter 41: f=0.0079136398
BFGS iter 42: f=0.007913287
BFGS iter 43: f=0.007912928
BFGS iter 44: f=0.0079128198
BFGS iter 45: f=0.0079127161
BFGS iter 46: f=0.0079126254
BFGS iter 47: f=0.0079125922
BFGS iter 48: f=0.0079125604
BFGS iter 49: f=0.007912419
BFGS iter 50: f=0.0079122915
BFGS iter 51: f=0.007912206
BFGS iter 52: f=0.0079121438
BFGS iter 53: f=0.0079121209
BFGS iter 54: f=0.0079121139
BFGS iter 55: f=0.0079121012
BFGS iter 56: f=0.0079120773
BFGS iter 57: f=0.007912057
BFGS iter 58: f=0.0079120208
BFGS iter 59: f=0.0079119448
BFGS iter 60: f=0.0079119083
BFGS iter 61: f=0.0079118957
BFGS iter 62: f=0.0079118891
BFGS iter 63: f=0.007911886
BFGS iter 64: f=0.007911885
BFGS iter 65: f=0.0079118841
BFGS iter 66: f=0.0079118828
BFGS iter 67: f=0.0079118768
BFGS iter 68: f=0.0079118688
BFGS iter 69: f=0.0079118606
*
BFGS iter 70: f=0.007938568
BFGS iter 71: f=0.0079364385
BFGS iter 72: f=0.0079336581
BFGS iter 73: f=0.007929901
BFGS iter 74: f=0.0079290534
BFGS iter 75: f=0.0079287777
BFGS iter 76: f=0.0079287307
BFGS iter 77: f=0.0079287168
BFGS iter 78: f=0.0079286926
BFGS iter 79: f=0.0079286668
BFGS iter 80: f=0.0079286556
BFGS iter 81: f=0.0079286522
BFGS iter 82: f=0.0079286507
BFGS iter 83: f=0.0079286497
BFGS iter 84: f=0.0079286488
BFGS iter 85: f=0.007928648
BFGS iter 86: f=0.0079286474
BFGS iter 87: f=0.0079286468
BFGS iter 88: f=0.0079286438
BFGS iter 89: f=0.0079286378
BFGS iter 90: f=0.007928625
BFGS iter 91: f=0.0079286172
BFGS iter 92: f=0.0079286148
BFGS iter 93: f=0.0079286137
BFGS iter 94: f=0.0079286136
BFGS iter 95: f=0.0079286136
BFGS iter 96: f=0.0079286136
BFGS iter 97: f=0.0079286136
BFGS iter 98: f=0.0079286136
BFGS iter 99: f=0.0079286136
*
BFGS iter 100: f=0.0079366535
BFGS iter 101: f=0.0079288146
BFGS iter 102: f=0.0079278279
BFGS iter 103: f=0.0079273971
BFGS iter 104: f=0.0079272981
BFGS iter 105: f=0.0079272873
BFGS iter 106: f=0.0079272852
BFGS iter 107: f=0.0079272838
BFGS iter 108: f=0.0079272835
BFGS iter 109: f=0.0079272834
BFGS iter 110: f=0.0079272833
BFGS iter 111: f=0.0079272832
BFGS iter 112: f=0.0079272828
BFGS iter 113: f=0.0079272816
BFGS iter 114: f=0.0079272761
BFGS iter 115: f=0.0079272753
BFGS iter 116: f=0.0079272751
BFGS iter 117: f=0.0079272746
BFGS iter 118: f=0.0079272689
BFGS iter 119: f=0.0079272318
BFGS iter 120: f=0.0079271966
BFGS iter 121: f=0.0079271508
BFGS iter 122: f=0.0079271051
BFGS iter 123: f=0.0079270527
BFGS iter 124: f=0.0079269823
BFGS iter 125: f=0.0079269411
BFGS iter 126: f=0.0079268912
BFGS iter 127: f=0.0079268511
BFGS iter 128: f=0.0079268181
BFGS iter 129: f=0.0079267875
BFGS iter 130: f=0.0079267638
BFGS iter 131: f=0.0079267413
BFGS iter 132: f=0.0079267194
BFGS iter 133: f=0.0079267085
BFGS iter 134: f=0.0079266832
BFGS iter 135: f=0.0079266609
BFGS iter 136: f=0.0079266406
BFGS iter 137: f=0.0079266254
BFGS iter 138: f=0.007926618
BFGS iter 139: f=0.0079265987
BFGS iter 140: f=0.0079265686
BFGS iter 141: f=0.0079265618
BFGS iter 142: f=0.0079265447
BFGS iter 143: f=0.0079265285
BFGS iter 144: f=0.0079264988
BFGS iter 145: f=0.0079264632
BFGS iter 146: f=0.0079264471
BFGS iter 147: f=0.0079264084
BFGS iter 148: f=0.0079263432
BFGS iter 149: f=0.0079262879
BFGS iter 150: f=0.0079227492
BFGS iter 151: f=0.0079148386
BFGS iter 152: f=0.0079140312
BFGS iter 153: f=0.0079138024
BFGS iter 154: f=0.0079136243
BFGS iter 155: f=0.0079135155
BFGS iter 156: f=0.0079134424
BFGS iter 157: f=0.0079133856
BFGS iter 158: f=0.0079132721
BFGS iter 159: f=0.0079132141
BFGS iter 160: f=0.0079131721
BFGS iter 161: f=0.007913143
BFGS iter 162: f=0.0079131
BFGS iter 163: f=0.0079130088
BFGS iter 164: f=0.0079129733
BFGS iter 165: f=0.0079129494
BFGS iter 166: f=0.0079129329
BFGS iter 167: f=0.0079129195
BFGS iter 168: f=0.0079129111
BFGS iter 169: f=0.0079129029
BFGS iter 170: f=0.0079128969
BFGS iter 171: f=0.0079128934
BFGS iter 172: f=0.0079128921
BFGS iter 173: f=0.0079128912
BFGS iter 174: f=0.0079128892
BFGS iter 175: f=0.0079128802
BFGS iter 176: f=0.0079128576
BFGS iter 177: f=0.0079128175
BFGS iter 178: f=0.0079127916
BFGS iter 179: f=0.0079127381
BFGS iter 180: f=0.0079127122
BFGS iter 181: f=0.0079126795
BFGS iter 182: f=0.0079126281
BFGS iter 183: f=0.0079126017
BFGS iter 184: f=0.0079125637
BFGS iter 185: f=0.0079124973
BFGS iter 186: f=0.0079124074
BFGS iter 187: f=0.0079123492
BFGS iter 188: f=0.0079122519
BFGS iter 189: f=0.0079122254
BFGS iter 190: f=0.0079122126
BFGS iter 191: f=0.0079122038
BFGS iter 192: f=0.0079121995
BFGS iter 193: f=0.0079121946
BFGS iter 194: f=0.0079121802
BFGS iter 195: f=0.0079121398
BFGS iter 196: f=0.0079120789
BFGS iter 197: f=0.007912055
BFGS iter 198: f=0.0079120272
BFGS iter 199: f=0.0079120078
BFGS iter 200: f=0.0079119973
BFGS iter 201: f=0.0079119869
BFGS iter 202: f=0.0079119761
BFGS iter 203: f=0.0079119566
BFGS iter 204: f=0.007911913
BFGS iter 205: f=0.0079118986
BFGS iter 206: f=0.0079118664
BFGS iter 207: f=0.0079118433
BFGS iter 208: f=0.0079118276
BFGS iter 209: f=0.0079118159
BFGS iter 210: f=0.007911797
BFGS iter 211: f=0.0079117713
BFGS iter 212: f=0.0079117524
BFGS iter 213: f=0.0079117186
BFGS iter 214: f=0.0079116864
BFGS iter 215: f=0.0079116359
BFGS iter 216: f=0.0079115979
BFGS iter 217: f=0.0079115527
BFGS iter 218: f=0.0079115089
BFGS iter 219: f=0.0079114729
BFGS iter 220: f=0.0079114329
BFGS iter 221: f=0.0079113884
BFGS iter 222: f=0.0079113629
BFGS iter 223: f=0.0079113071
BFGS iter 224: f=0.0079112734
BFGS iter 225: f=0.0079112055
BFGS iter 226: f=0.0079111583
BFGS iter 227: f=0.0079111089
BFGS iter 228: f=0.0079110597
BFGS iter 229: f=0.0079110146
BFGS iter 230: f=0.0079109795
BFGS iter 231: f=0.0079109264
BFGS iter 232: f=0.0079109048
BFGS iter 233: f=0.0079108766
BFGS iter 234: f=0.007910853
BFGS iter 235: f=0.0079108324
BFGS iter 236: f=0.007910823
BFGS iter 237: f=0.0079108171
BFGS iter 238: f=0.0079108064
BFGS iter 239: f=0.0079107949
BFGS iter 240: f=0.0079107797
BFGS iter 241: f=0.0079107706
BFGS iter 242: f=0.0079107656
BFGS iter 243: f=0.0079107632
BFGS iter 244: f=0.0079107608
BFGS iter 245: f=0.0079107569
BFGS iter 246: f=0.0079107508
BFGS iter 247: f=0.0079107446
BFGS iter 248: f=0.0079107381
BFGS iter 249: f=0.0079107348
BFGS ended due to small decr. in 50 iterations
MTPR training ended
Rescaling...
   scaling = 0.052321907, condition number = 19.768641
   scaling = 0.057078444, condition number = 15.492339
   scaling = 0.062786289, condition number = 14.719276
   scaling = 0.069064917, condition number = 14.427115
   scaling = 0.075343546, condition number = 17.312415
Rescaling to 0.069064917... done
Rescaling...
   scaling = 0.057554098, condition number = 15.247638
   scaling = 0.062786289, condition number = 14.719276
   scaling = 0.069064917, condition number = 14.427115
   scaling = 0.075971409, condition number = 17.331904
   scaling = 0.082877901, condition number = 17.928589
Rescaling to 0.069064917... done
_________________Errors report_________________
Energy:
	Errors checked for 353 configurations
	Maximal absolute difference = 0.223121
	Average absolute difference = 0.0569171
	RMS     absolute difference = 0.0988419

Energy per atom:
	Errors checked for 353 configurations
	Maximal absolute difference = 0.111561
	Average absolute difference = 0.028541
	RMS     absolute difference = 0.0494348

Forces:
	Errors checked for 696 atoms
	Maximal absolute difference = 0.134315
	Average absolute difference = 0.0511518
	RMS     absolute difference = 0.0713887
	Max(ForceDiff) / Max(Force) = 0.0557073
	RMS(ForceDiff) / RMS(Force) = 0.0506926

Stresses (in energy units):
	Errors checked for 353 configurations
	Maximal absolute difference = 2.89609
	Average absolute difference = 1.68089
	RMS     absolute difference = 1.89212
	Max(StresDiff) / Max(Stres) = 0.496181
	RMS(StresDiff) / RMS(Stres) = 0.362858

Virial stresses (in pressure units):
	Errors checked for 353 configurations
	Maximal absolute difference = 74.6265
	Average absolute difference = 41.2579
	RMS     absolute difference = 46.8354
	Max(StresDiff) / Max(Stres) = 0.481296
	RMS(StresDiff) / RMS(Stres) = 0.357757
_______________________________________________

	batch_size = 9999
	swap_limit = 0
	weight_scaling = 2
	energy_weight = 1.000000
	force_weight = 0.000000
	init_value = 0.000001
	site_en_weight = 0.000000
	stress_weight = 0.000000
	threshold = 1.001000
Selection: state saved to "mtp_V36.mtp"
training complete
