Selection data found
Basic trainer initialization complete
	auto-minmax-magmom = false
	init_random = false
	no_mindist_update = false
	skip_preinit = false
	iteration_limit = 1000
	weight_scaling = 1
	weight_scaling_forces = 0
	energy_weight = 1.000000
	force_weight = 0.010000
	penalty_weight = 0.000001
	scale_by_force = 0.000000
	select_factor = 1.000000
	stress_weight = 0.001000
	tolerance = 0.001000
	log = stdout
	save_to = mtp_V34.mtp
335 configurations found in the training set
Minimal interatomic distance in the training set is 1.54422. MTP's mindist will be updated
Iteration limit is 1000
Convergence tolerance is 0.001
Energy weight: 1
Force weight: 0.01
Stress weight: 0.001
MTPR training started on 1 core(s)
BFGS iter 0: f=0.243927
BFGS iter 1: f=0.243927
BFGS iter 2: f=0.243927
BFGS iter 3: f=0.243927
BFGS iter 4: f=0.243926
BFGS iter 5: f=0.243926
BFGS iter 6: f=0.243926
BFGS iter 7: f=0.243926
BFGS iter 8: f=0.243926
BFGS iter 9: f=0.243926
BFGS iter 10: f=0.243925
BFGS iter 11: f=0.243925
BFGS iter 12: f=0.243925
BFGS iter 13: f=0.243924
BFGS iter 14: f=0.243923
BFGS iter 15: f=0.243923
BFGS iter 16: f=0.243922
BFGS iter 17: f=0.243921
BFGS iter 18: f=0.243919
BFGS iter 19: f=0.243917
BFGS iter 20: f=0.243916
BFGS iter 21: f=0.243916
BFGS iter 22: f=0.243916
BFGS iter 23: f=0.243915
BFGS iter 24: f=0.243915
BFGS iter 25: f=0.0075263324
BFGS iter 26: f=0.0075263113
BFGS iter 27: f=0.0075262251
BFGS iter 28: f=0.0075261741
BFGS iter 29: f=0.0075252637
BFGS iter 30: f=0.0075252283
BFGS iter 31: f=0.0075250502
BFGS iter 32: f=0.0075249462
BFGS iter 33: f=0.0075248517
BFGS iter 34: f=0.0075248193
BFGS iter 35: f=0.0075247076
BFGS iter 36: f=0.0075243604
BFGS iter 37: f=0.0075240012
BFGS iter 38: f=0.007523249
BFGS iter 39: f=0.0075222157
BFGS iter 40: f=0.0075220484
BFGS iter 41: f=0.0075213664
BFGS iter 42: f=0.0075210509
BFGS iter 43: f=0.007520191
BFGS iter 44: f=0.0075191608
BFGS iter 45: f=0.0075189486
BFGS iter 46: f=0.007518662
BFGS iter 47: f=0.0075184638
BFGS iter 48: f=0.0075177633
BFGS iter 49: f=0.0075172163
BFGS iter 50: f=0.007516613
BFGS iter 51: f=0.0075160684
BFGS iter 52: f=0.0075157315
BFGS iter 53: f=0.0075155699
BFGS iter 54: f=0.0075154187
BFGS iter 55: f=0.0075152924
BFGS iter 56: f=0.0075151967
BFGS iter 57: f=0.0075151048
BFGS iter 58: f=0.0075150156
BFGS iter 59: f=0.0075148798
BFGS iter 60: f=0.0075147205
BFGS iter 61: f=0.0075145051
BFGS iter 62: f=0.0075144581
BFGS iter 63: f=0.0075143905
BFGS iter 64: f=0.0075143588
BFGS iter 65: f=0.0075143412
BFGS iter 66: f=0.0075143199
BFGS iter 67: f=0.0075142856
BFGS iter 68: f=0.0075142587
BFGS iter 69: f=0.0075142461
BFGS iter 70: f=0.0074707177
BFGS iter 71: f=0.0074695522
BFGS iter 72: f=0.0074688398
BFGS iter 73: f=0.0074679126
BFGS iter 74: f=0.0074667722
BFGS iter 75: f=0.0074666172
BFGS iter 76: f=0.0074662133
BFGS iter 77: f=0.0074658381
BFGS iter 78: f=0.0074652946
BFGS iter 79: f=0.0074649977
BFGS iter 80: f=0.007464878
BFGS iter 81: f=0.0074646978
BFGS iter 82: f=0.0074643327
BFGS iter 83: f=0.0074637611
BFGS iter 84: f=0.0074636939
BFGS iter 85: f=0.0074636567
BFGS iter 86: f=0.0074636336
BFGS iter 87: f=0.0074636219
BFGS iter 88: f=0.0074636103
BFGS iter 89: f=0.0074635579
BFGS iter 90: f=0.0074635215
BFGS iter 91: f=0.007463511
BFGS iter 92: f=0.0074635083
BFGS iter 93: f=0.0074635038
BFGS iter 94: f=0.0074634822
BFGS iter 95: f=0.0074634734
BFGS iter 96: f=0.0074634575
BFGS iter 97: f=0.0074633977
BFGS iter 98: f=0.0074633159
BFGS iter 99: f=0.0074632749
BFGS iter 100: f=0.0074614659
BFGS iter 101: f=0.0074608227
BFGS iter 102: f=0.0074586675
BFGS iter 103: f=0.0074583749
BFGS iter 104: f=0.0074580379
BFGS iter 105: f=0.0074576175
BFGS iter 106: f=0.0074573673
BFGS iter 107: f=0.0074573379
BFGS iter 108: f=0.0074573233
BFGS iter 109: f=0.007457312
BFGS iter 110: f=0.0074572988
BFGS iter 111: f=0.0074572856
BFGS iter 112: f=0.0074572721
BFGS iter 113: f=0.0074572487
BFGS iter 114: f=0.007457204
BFGS iter 115: f=0.0074571826
BFGS iter 116: f=0.0074571788
BFGS iter 117: f=0.007457177
BFGS iter 118: f=0.0074571763
BFGS iter 119: f=0.0074571758
BFGS iter 120: f=0.0074571743
BFGS iter 121: f=0.0074571603
BFGS iter 122: f=0.0074568617
BFGS iter 123: f=0.0074567443
BFGS iter 124: f=0.0074566201
BFGS iter 125: f=0.0074565957
BFGS iter 126: f=0.0074565626
BFGS iter 127: f=0.0074565299
BFGS iter 128: f=0.007456518
BFGS iter 129: f=0.0074565138
BFGS iter 130: f=0.0074565107
BFGS iter 131: f=0.00745651
BFGS iter 132: f=0.007456509
BFGS iter 133: f=0.0074565082
BFGS iter 134: f=0.0074565076
BFGS iter 135: f=0.0074565076
BFGS iter 136: f=0.0074565075
BFGS iter 137: f=0.0074565075
BFGS iter 138: f=0.0074565075
BFGS iter 139: f=0.0074565075
BFGS iter 140: f=0.0074565075
BFGS iter 141: f=0.0074565067
BFGS iter 142: f=0.0074564936
BFGS iter 143: f=0.0074564281
BFGS iter 144: f=0.0074563129
BFGS iter 145: f=0.0074561865
BFGS iter 146: f=0.0074559013
BFGS iter 147: f=0.0074556875
BFGS iter 148: f=0.0074555824
BFGS iter 149: f=0.0074554154
BFGS iter 150: f=0.0074536333
BFGS iter 151: f=0.0074527537
BFGS iter 152: f=0.0074518837
BFGS iter 153: f=0.0074502215
BFGS iter 154: f=0.0074494566
BFGS iter 155: f=0.0074490973
BFGS iter 156: f=0.0074489277
BFGS iter 157: f=0.0074487479
BFGS iter 158: f=0.0074486012
BFGS iter 159: f=0.0074484993
BFGS iter 160: f=0.0074484146
BFGS iter 161: f=0.0074483499
BFGS iter 162: f=0.0074483339
BFGS iter 163: f=0.0074483299
BFGS iter 164: f=0.0074483264
BFGS iter 165: f=0.007448314
BFGS iter 166: f=0.0074483022
BFGS iter 167: f=0.0074482786
BFGS iter 168: f=0.0074482063
BFGS iter 169: f=0.0074481393
BFGS iter 170: f=0.0074480379
BFGS iter 171: f=0.0074479817
BFGS iter 172: f=0.0074479529
BFGS iter 173: f=0.0074479351
BFGS iter 174: f=0.0074479239
BFGS iter 175: f=0.0074479153
BFGS iter 176: f=0.0074479078
BFGS iter 177: f=0.0074479014
BFGS iter 178: f=0.0074478967
BFGS iter 179: f=0.0074478915
BFGS iter 180: f=0.0074478824
BFGS iter 181: f=0.0074478384
BFGS iter 182: f=0.0074477877
BFGS iter 183: f=0.007447676
BFGS iter 184: f=0.0074475259
BFGS iter 185: f=0.0074473916
BFGS iter 186: f=0.0074473035
BFGS iter 187: f=0.007447258
BFGS iter 188: f=0.0074471983
BFGS iter 189: f=0.0074471443
BFGS iter 190: f=0.0074471122
BFGS iter 191: f=0.0074470703
BFGS iter 192: f=0.0074470451
BFGS iter 193: f=0.0074469705
BFGS iter 194: f=0.0074469083
BFGS iter 195: f=0.0074467527
BFGS iter 196: f=0.0074465873
BFGS iter 197: f=0.0074464187
BFGS iter 198: f=0.0074463169
BFGS iter 199: f=0.0074462455
BFGS iter 200: f=0.0074461774
BFGS iter 201: f=0.0074461457
BFGS iter 202: f=0.0074461255
BFGS iter 203: f=0.0074461071
BFGS iter 204: f=0.0074460912
BFGS iter 205: f=0.007446084
BFGS iter 206: f=0.0074460771
BFGS iter 207: f=0.0074460685
BFGS iter 208: f=0.0074460607
BFGS iter 209: f=0.0074460575
BFGS iter 210: f=0.007446055
BFGS iter 211: f=0.0074460493
BFGS iter 212: f=0.0074460432
BFGS iter 213: f=0.0074460398
BFGS iter 214: f=0.0074460379
BFGS iter 215: f=0.0074460347
BFGS iter 216: f=0.0074460285
BFGS iter 217: f=0.0074460109
BFGS iter 218: f=0.0074459463
BFGS iter 219: f=0.0074458899
BFGS iter 220: f=0.0074458125
BFGS iter 221: f=0.0074457627
BFGS iter 222: f=0.0074457222
BFGS iter 223: f=0.0074456896
BFGS iter 224: f=0.0074456688
BFGS iter 225: f=0.0074456434
BFGS iter 226: f=0.007445633
BFGS iter 227: f=0.0074456222
BFGS iter 228: f=0.0074456157
BFGS iter 229: f=0.0074456083
BFGS iter 230: f=0.0074456024
BFGS iter 231: f=0.0074455967
BFGS iter 232: f=0.0074455848
BFGS iter 233: f=0.0074455643
BFGS iter 234: f=0.0074455465
BFGS iter 235: f=0.0074455046
BFGS iter 236: f=0.007445488
BFGS iter 237: f=0.00744543
BFGS iter 238: f=0.0074453446
BFGS iter 239: f=0.0074453127
BFGS iter 240: f=0.0074452837
BFGS iter 241: f=0.0074452671
BFGS iter 242: f=0.0074452606
BFGS iter 243: f=0.0074452524
BFGS iter 244: f=0.0074452474
BFGS iter 245: f=0.0074452453
BFGS iter 246: f=0.0074452437
BFGS iter 247: f=0.0074452416
BFGS iter 248: f=0.0074452383
BFGS iter 249: f=0.007445225
BFGS ended due to small decr. in 50 iterations
MTPR training ended
Rescaling...
   scaling = 0.057554098, condition number = 14.727862
   scaling = 0.062786289, condition number = 13.881681
   scaling = 0.069064917, condition number = 15.711592
   scaling = 0.075971409, condition number = 18.051399
   scaling = 0.082877901, condition number = 18.901307
Rescaling to 0.062786289... done
Rescaling...
   scaling = 0.052321907, condition number = 15.359316
   scaling = 0.057078444, condition number = 14.777664
   scaling = 0.062786289, condition number = 13.881681
   scaling = 0.069064917, condition number = 15.711592
   scaling = 0.075343546, condition number = 18.014396
Rescaling to 0.062786289... done
_________________Errors report_________________
Energy:
	Errors checked for 335 configurations
	Maximal absolute difference = 0.214879
	Average absolute difference = 0.0573264
	RMS     absolute difference = 0.0980624

Energy per atom:
	Errors checked for 335 configurations
	Maximal absolute difference = 0.10744
	Average absolute difference = 0.0287674
	RMS     absolute difference = 0.0490447

Forces:
	Errors checked for 660 atoms
	Maximal absolute difference = 0.146353
	Average absolute difference = 0.0568468
	RMS     absolute difference = 0.0785392
	Max(ForceDiff) / Max(Force) = 0.0606999
	RMS(ForceDiff) / RMS(Force) = 0.055883

Stresses (in energy units):
	Errors checked for 335 configurations
	Maximal absolute difference = 3.17147
	Average absolute difference = 1.7276
	RMS     absolute difference = 1.948
	Max(StresDiff) / Max(Stres) = 0.543361
	RMS(StresDiff) / RMS(Stres) = 0.373874

Virial stresses (in pressure units):
	Errors checked for 335 configurations
	Maximal absolute difference = 81.7224
	Average absolute difference = 42.4242
	RMS     absolute difference = 48.345
	Max(StresDiff) / Max(Stres) = 0.527061
	RMS(StresDiff) / RMS(Stres) = 0.369589
_______________________________________________

	batch_size = 9999
	swap_limit = 0
	weight_scaling = 2
	energy_weight = 1.000000
	force_weight = 0.000000
	init_value = 0.000001
	site_en_weight = 0.000000
	stress_weight = 0.000000
	threshold = 1.001000
Selection: state saved to "mtp_V34.mtp"
training complete
